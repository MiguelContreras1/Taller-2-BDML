> lasso
glmnet 

164960 samples
     8 predictor

Pre-processing: centered (16), scaled (16) 
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 148464, 148463, 148464, 148464, 148463, 148464, ... 
Resampling results across tuning parameters:

  lambda        RMSE     Rsquared   MAE    
  1.000000e-02  2167996  0.2578326  1166245
  1.123324e-02  2167996  0.2578326  1166245
  1.261857e-02  2167996  0.2578326  1166245
  1.417474e-02  2167996  0.2578326  1166245
  1.592283e-02  2167996  0.2578326  1166245
  1.788650e-02  2167996  0.2578326  1166245
  2.009233e-02  2167996  0.2578326  1166245
  2.257020e-02  2167996  0.2578326  1166245
  2.535364e-02  2167996  0.2578326  1166245
  2.848036e-02  2167996  0.2578326  1166245
  3.199267e-02  2167996  0.2578326  1166245
  3.593814e-02  2167996  0.2578326  1166245
  4.037017e-02  2167996  0.2578326  1166245
  4.534879e-02  2167996  0.2578326  1166245
  5.094138e-02  2167996  0.2578326  1166245
  5.722368e-02  2167996  0.2578326  1166245
  6.428073e-02  2167996  0.2578326  1166245
  7.220809e-02  2167996  0.2578326  1166245
  8.111308e-02  2167996  0.2578326  1166245
  9.111628e-02  2167996  0.2578326  1166245
  1.023531e-01  2167996  0.2578326  1166245
  1.149757e-01  2167996  0.2578326  1166245
  1.291550e-01  2167996  0.2578326  1166245
  1.450829e-01  2167996  0.2578326  1166245
  1.629751e-01  2167996  0.2578326  1166245
  1.830738e-01  2167996  0.2578326  1166245
  2.056512e-01  2167996  0.2578326  1166245
  2.310130e-01  2167996  0.2578326  1166245
  2.595024e-01  2167996  0.2578326  1166245
  2.915053e-01  2167996  0.2578326  1166245
  3.274549e-01  2167996  0.2578326  1166245
  3.678380e-01  2167996  0.2578326  1166245
  4.132012e-01  2167996  0.2578326  1166245
  4.641589e-01  2167996  0.2578326  1166245
  5.214008e-01  2167996  0.2578326  1166245
  5.857021e-01  2167996  0.2578326  1166245
  6.579332e-01  2167996  0.2578326  1166245
  7.390722e-01  2167996  0.2578326  1166245
  8.302176e-01  2167996  0.2578326  1166245
  9.326033e-01  2167996  0.2578326  1166245
  1.047616e+00  2167996  0.2578326  1166245
  1.176812e+00  2167996  0.2578326  1166245
  1.321941e+00  2167996  0.2578326  1166245
  1.484968e+00  2167996  0.2578326  1166245
  1.668101e+00  2167996  0.2578326  1166245
  1.873817e+00  2167996  0.2578326  1166245
  2.104904e+00  2167996  0.2578326  1166245
  2.364489e+00  2167996  0.2578326  1166245
  2.656088e+00  2167996  0.2578326  1166245
  2.983647e+00  2167996  0.2578326  1166245
  3.351603e+00  2167996  0.2578326  1166245
  3.764936e+00  2167996  0.2578326  1166245
  4.229243e+00  2167996  0.2578326  1166245
  4.750810e+00  2167996  0.2578326  1166245
  5.336699e+00  2167996  0.2578326  1166245
  5.994843e+00  2167996  0.2578326  1166245
  6.734151e+00  2167996  0.2578326  1166245
  7.564633e+00  2167996  0.2578326  1166245
  8.497534e+00  2167996  0.2578326  1166245
  9.545485e+00  2167996  0.2578326  1166245
  1.072267e+01  2167996  0.2578326  1166245
  1.204504e+01  2167996  0.2578326  1166245
  1.353048e+01  2167996  0.2578326  1166245
  1.519911e+01  2167996  0.2578326  1166245
  1.707353e+01  2167996  0.2578326  1166245
  1.917910e+01  2167996  0.2578326  1166245
  2.154435e+01  2167996  0.2578326  1166245
  2.420128e+01  2167996  0.2578326  1166245
  2.718588e+01  2167996  0.2578326  1166245
  3.053856e+01  2167996  0.2578326  1166245
  3.430469e+01  2167996  0.2578326  1166245
  3.853529e+01  2167996  0.2578326  1166245
  4.328761e+01  2167996  0.2578326  1166245
  4.862602e+01  2167996  0.2578326  1166245
  5.462277e+01  2167996  0.2578326  1166245
  6.135907e+01  2167996  0.2578326  1166245
  6.892612e+01  2167996  0.2578326  1166245
  7.742637e+01  2167996  0.2578326  1166245
  8.697490e+01  2167996  0.2578326  1166245
  9.770100e+01  2167996  0.2578326  1166245
  1.097499e+02  2167996  0.2578326  1166245
  1.232847e+02  2167996  0.2578326  1166245
  1.384886e+02  2167996  0.2578326  1166245
  1.555676e+02  2167996  0.2578326  1166245
  1.747528e+02  2167996  0.2578326  1166245
  1.963041e+02  2167996  0.2578326  1166245
  2.205131e+02  2167996  0.2578326  1166245
  2.477076e+02  2167996  0.2578326  1166245
  2.782559e+02  2167996  0.2578326  1166245
  3.125716e+02  2167996  0.2578326  1166245
  3.511192e+02  2167996  0.2578326  1166245
  3.944206e+02  2167996  0.2578326  1166245
  4.430621e+02  2167996  0.2578326  1166245
  4.977024e+02  2167996  0.2578326  1166245
  5.590810e+02  2167996  0.2578326  1166245
  6.280291e+02  2167996  0.2578326  1166245
  7.054802e+02  2167996  0.2578326  1166245
  7.924829e+02  2167996  0.2578326  1166245
  8.902151e+02  2167997  0.2578321  1166228
  1.000000e+03  2168001  0.2578294  1166155

Tuning parameter 'alpha' was held constant at a value of 1
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were alpha = 1 and lambda = 792.4829.